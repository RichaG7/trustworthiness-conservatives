{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed235f2b-33eb-4e32-8be5-6edbdd05030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57535d2a-61aa-481b-b145-75ece5868430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../resources/faces/instructions/CFD-WM-025-002-N.jpg']\n",
      "['../resources/faces/training/CFD-WM-223-056-N.jpg', '../resources/faces/training/CFD-WM-236-072-N.jpg', '../resources/faces/training/CFD-WM-037-025-N.jpg', '../resources/faces/training/CFD-WM-220-068-N.jpg']\n",
      "['../resources/faces/testing/CFD-WM-029-023-N.jpg', '../resources/faces/testing/CFD-WM-040-022-N.jpg', '../resources/faces/testing/CFD-WM-035-032-N.jpg', '../resources/faces/testing/CFD-WM-217-070-N.jpg', '../resources/faces/testing/CFD-WM-235-147-N.jpg', '../resources/faces/testing/CFD-WM-031-003-N.jpg', '../resources/faces/testing/CFD-WM-010-001-N.jpg', '../resources/faces/testing/CFD-WM-245-123-N.jpg', '../resources/faces/testing/CFD-WM-253-119-N.jpg', '../resources/faces/testing/CFD-WM-219-008-N.jpg', '../resources/faces/testing/CFD-WM-252-224-N.jpg', '../resources/faces/testing/CFD-WM-242-011-N.jpg', '../resources/faces/testing/CFD-WM-248-036-N.jpg', '../resources/faces/testing/CFD-WM-213-076-N.jpg', '../resources/faces/testing/CFD-WM-015-002-N.jpg', '../resources/faces/testing/CFD-WM-033-025-N.jpg']\n",
      "['../resources/faces/attentioncheck/CFD-WM-001-014-N.jpg']\n"
     ]
    }
   ],
   "source": [
    "instructions_sentences = glob.glob('../resources/sentences/instructions/*.csv', recursive=False)\n",
    "instructions_face = glob.glob('../resources/faces/instructions/*.jpg', recursive=False)\n",
    "\n",
    "training_sentences = glob.glob('../resources/sentences/training/*.csv', recursive=False)\n",
    "training_faces = glob.glob('../resources/faces/training/*.jpg', recursive=False)\n",
    "\n",
    "testing_sentences = glob.glob('../resources/sentences/testing/used_sentences_final.csv', recursive=False)\n",
    "testing_faces = glob.glob('../resources/faces/testing/*.jpg', recursive=False)\n",
    "\n",
    "attentioncheck_face = glob.glob('../resources/faces/attentioncheck/*.jpg', recursive=False)\n",
    "\n",
    "print(instructions_face)\n",
    "print(training_faces)\n",
    "print(testing_faces)\n",
    "print(attentioncheck_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c72900-8f52-485b-9aee-80ce497af3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instructions': [['../resources/faces/instructions/CFD-WM-025-002-N.jpg',\n",
       "   'It is common sense that divisive ideologies weaken the social fabric.']]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = {}\n",
    "for instruction in instructions_sentences:\n",
    "    instruction_df = pd.read_csv(instruction, encoding=\"mac_roman\")\n",
    "\n",
    "    sentence_instructions = instruction_df.Text.tolist()\n",
    "    \n",
    "    if \"instructions\" not in instructions.keys():\n",
    "        instructions[\"instructions\"] = []\n",
    "        \n",
    "    for i in np.arange(len(sentence_instructions)):\n",
    "        instructions[\"instructions\"].append([instructions_face[i], sentence_instructions[i]])\n",
    "\n",
    "instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a9bf34-84db-4079-8bda-54779d89ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_con = {}\n",
    "training_lib = {}\n",
    "\n",
    "for training_sentence in training_sentences:\n",
    "    training_sentence_df = pd.read_csv(training_sentence, encoding=\"mac_roman\")\n",
    "    training_sentence_df_con = training_sentence_df[training_sentence_df.PoliticalIdeology == \"Conservative\"]\n",
    "    training_sentence_df_lib = training_sentence_df[training_sentence_df.PoliticalIdeology == \"Liberal\"]\n",
    "    \n",
    "    sentences_con = training_sentence_df_con.Text.tolist()\n",
    "    sentences_lib = training_sentence_df_lib.Text.tolist()\n",
    "\n",
    "    con_combos = {}\n",
    "    lib_combos = {}\n",
    "    \n",
    "    for i in np.arange(len(training_faces)):\n",
    "        if f\"combination_face{i+1}\" not in con_combos.keys():\n",
    "            con_combos[f\"combination_face{i+1}\"] = []\n",
    "        for j in np.arange(len(sentences_con)):\n",
    "            combo = [training_faces[i], sentences_con[j]]\n",
    "            con_combos[f\"combination_face{i+1}\"].append(combo)\n",
    "    \n",
    "    for i in np.arange(len(training_faces)):\n",
    "        if f\"combination_face{i+1}\" not in lib_combos.keys():\n",
    "            lib_combos[f\"combination_face{i+1}\"] = []\n",
    "        for j in np.arange(len(sentences_lib)):\n",
    "            combo = [training_faces[i], sentences_lib[j]]\n",
    "            lib_combos[f\"combination_face{i+1}\"].append(combo)\n",
    "\n",
    "    for i in np.arange(len(con_combos.keys())):\n",
    "        if f\"combination{i+1}\" not in training_con.keys():\n",
    "            training_con[f\"combination{i+1}\"] = []\n",
    "        for j in np.arange(len(con_combos.keys())):\n",
    "            k = j + i\n",
    "            training_con[f\"combination{i+1}\"].append(con_combos[f'combination_face{j+1}'][max(np.arange(len(con_combos))) - k])\n",
    "            \n",
    "    for i in np.arange(len(lib_combos.keys())):\n",
    "        if f\"combination{i+1}\" not in training_lib.keys():\n",
    "            training_lib[f\"combination{i+1}\"] = []\n",
    "        for j in np.arange(len(lib_combos.keys())):\n",
    "            k = j + i\n",
    "            training_lib[f\"combination{i+1}\"].append(lib_combos[f'combination_face{j+1}'][max(np.arange(len(lib_combos))) - k])\n",
    "\n",
    "# print(f\"{training_con}\\n\\n\")\n",
    "# print(f\"{training_lib}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80619133-8b62-42a6-b3af-625e32d716b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_con = {}\n",
    "testing_lib = {}\n",
    "\n",
    "for testing_sentence in testing_sentences:\n",
    "    testing_sentence_df = pd.read_csv(testing_sentence, encoding=\"mac_roman\")\n",
    "    testing_sentence_df_con = testing_sentence_df[testing_sentence_df.PoliticalIdeology == \"Conservative\"]\n",
    "    testing_sentence_df_lib = testing_sentence_df[testing_sentence_df.PoliticalIdeology == \"Liberal\"]\n",
    "    \n",
    "    sentences_con = testing_sentence_df_con.Text.tolist()\n",
    "    sentences_lib = testing_sentence_df_lib.Text.tolist()\n",
    "\n",
    "    con_combos = {}\n",
    "    lib_combos = {}\n",
    "    \n",
    "    for i in np.arange(len(testing_faces)):\n",
    "        if f\"combination_face{i+1}\" not in con_combos.keys():\n",
    "            con_combos[f\"combination_face{i+1}\"] = []\n",
    "        for j in np.arange(len(sentences_con)):\n",
    "            combo = [testing_faces[i], sentences_con[j]]\n",
    "            con_combos[f\"combination_face{i+1}\"].append(combo)\n",
    "    \n",
    "    for i in np.arange(len(testing_faces)):\n",
    "        if f\"combination_face{i+1}\" not in lib_combos.keys():\n",
    "            lib_combos[f\"combination_face{i+1}\"] = []\n",
    "        for j in np.arange(len(sentences_lib)):\n",
    "            combo = [testing_faces[i], sentences_lib[j]]\n",
    "            lib_combos[f\"combination_face{i+1}\"].append(combo)\n",
    "\n",
    "    for i in np.arange(len(con_combos.keys())):\n",
    "        if f\"combination{i+1}\" not in testing_con.keys():\n",
    "            testing_con[f\"combination{i+1}\"] = []\n",
    "        for j in np.arange(len(con_combos.keys())):\n",
    "            k = j + i\n",
    "            testing_con[f\"combination{i+1}\"].append(con_combos[f'combination_face{j+1}'][max(np.arange(len(con_combos))) - k])\n",
    "            \n",
    "    for i in np.arange(len(lib_combos.keys())):\n",
    "        if f\"combination{i+1}\" not in testing_lib.keys():\n",
    "            testing_lib[f\"combination{i+1}\"] = []\n",
    "        for j in np.arange(len(lib_combos.keys())):\n",
    "            k = j + i\n",
    "            testing_lib[f\"combination{i+1}\"].append(lib_combos[f'combination_face{j+1}'][max(np.arange(len(lib_combos))) - k])\n",
    "\n",
    "\n",
    "# print(f\"{testing_con}\\n\\n\")\n",
    "# print(f\"{testing_lib}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dec66de-f9b6-4e61-89b4-df602d0c6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "attentioncheck = {'attentioncheck': [[attentioncheck_face[0], 'Please press \"E\" for this trial']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3831ef4-8916-412a-9a63-80d67a1fdd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_instructions = [{'instructions': instructions}]\n",
    "stimuli_con = [{\"training_con\":training_con}, {\"testing_con\":testing_con}, {'attentioncheck': attentioncheck}]\n",
    "stimuli_lib = [{\"training_lib\":training_lib}, {\"testing_lib\":testing_lib}, {'attentioncheck': attentioncheck}]\n",
    "stimuli_attentioncheck = [{'attentioncheck': attentioncheck}]\n",
    "\n",
    "with open(f\"../resources/jsons/instructions/stimuli_instructions.json\", \"w\") as f:\n",
    "    json.dump(stimuli_instructions, f)   \n",
    "    \n",
    "with open(f\"../resources/jsons/conservative/stimuli_con.json\", \"w\") as f:\n",
    "    json.dump(stimuli_con, f) \n",
    "    \n",
    "with open(f\"../resources/jsons/liberal/stimuli_lib.json\", \"w\") as f:\n",
    "    json.dump(stimuli_lib, f)   \n",
    "\n",
    "with open(f\"../resources/jsons/attentioncheck/stimuli_attentioncheck.json\", \"w\") as f:\n",
    "    json.dump(stimuli_attentioncheck, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9214f-71f1-437e-aa7f-730e7a9a43cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3dd17-cc56-4acb-a233-2b4630c43228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
